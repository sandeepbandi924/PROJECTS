{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('St_Paul_hospital_train.csv')  # Adjust path if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_text</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sensory ataxic hemiparesis in thalamic hemorrh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An analysis of abnormalities of the retinoblas...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enteric neuronal autoantibodies in pseudoobstr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scintigraphic measurement of oropharyngeal tra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tissue origin of low back pain and sciatic...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        medical_text  diagnosis\n",
       "0  Sensory ataxic hemiparesis in thalamic hemorrh...          5\n",
       "1  An analysis of abnormalities of the retinoblas...          5\n",
       "2  Enteric neuronal autoantibodies in pseudoobstr...          2\n",
       "3  Scintigraphic measurement of oropharyngeal tra...          3\n",
       "4  The tissue origin of low back pain and sciatic...          5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data: 70% training, 15% validation, 15% test\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7074\n",
      "Validation set size: 1516\n",
      "Test set size: 1516\n"
     ]
    }
   ],
   "source": [
    "# Display the sizes of each partition\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full implementation for training the Char-RNN\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the text data into a single string\n",
    "text = \" \".join(train_data['medical_text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create character-to-index and index-to-character mappings\n",
    "chars = sorted(set(text))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "# Convert the entire text into a sequence of integer indices\n",
    "input_text = [char_to_idx[char] for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare sequences and labels for training\n",
    "seq_length = 100  # Length of each sequence for training\n",
    "sequences = [input_text[i: i + seq_length + 1] for i in range(len(input_text) - seq_length)]\n",
    "X = np.array([sequence[:-1] for sequence in sequences])  # Input sequences\n",
    "y = np.array([sequence[-1] for sequence in sequences])   # Next character as label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Char-RNN Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(chars), output_dim=64, input_length=seq_length),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(128),\n",
    "    Dense(len(chars), activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the model\n",
    "history = model.fit(X, y, epochs=10, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate synthetic text\n",
    "def generate_text(model, start_text, gen_length=200):\n",
    "    # Convert start_text to character indices\n",
    "    input_eval = [char_to_idx[char] for char in start_text]\n",
    "    generated_text = start_text\n",
    "\n",
    "    for _ in range(gen_length):\n",
    "        # Pad the input sequence to the required length\n",
    "        input_eval_padded = pad_sequences([input_eval], maxlen=seq_length, padding=\"pre\")\n",
    "        \n",
    "        # Predict the next character index\n",
    "        predictions = model.predict(input_eval_padded, verbose=0)\n",
    "        predicted_id = np.argmax(predictions[-1])\n",
    "        \n",
    "        # Append the predicted character to generated_text\n",
    "        generated_text += idx_to_char[predicted_id]\n",
    "        \n",
    "        # Update input sequence for the next prediction\n",
    "        input_eval.append(predicted_id)\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sample of synthetic medical text\n",
    "start_text = \"Patient presents with \"\n",
    "print(generate_text(model, start_text=start_text, gen_length=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2: Diagnosis Classification with Sequential RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['text_column'])\n",
    "X_train = tokenizer.texts_to_sequences(train_data['text_column'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['text_column'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "max_length = 100\n",
    "X_train_padded = pad_sequences(X_train, maxlen=max_length, padding=\"post\")\n",
    "X_test_padded = pad_sequences(X_test, maxlen=max_length, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model definition\n",
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_length),\n",
    "    GRU(64),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "history_rnn = model_rnn.fit(X_train_padded, train_data['label_column'], epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data['text_column']).toarray()\n",
    "X_test_tfidf = vectorizer.transform(test_data['text_column']).toarray()\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_tfidf, train_data['label_column'])\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(test_data['label_column'], y_pred)\n",
    "print(\"Bag-of-Words Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine predictions from the RNN model and Bag-of-Words model using a simple ensemble approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train ensemble model with Logistic Regression and Random Forest\n",
    "ensemble_clf = VotingClassifier(estimators=[\n",
    "    ('rnn', LogisticRegression()),  # Use logistic regression for simplicity\n",
    "    ('rf', rf_classifier)\n",
    "], voting='soft')\n",
    "\n",
    "ensemble_clf.fit(X_train_tfidf, train_data['label_column'])\n",
    "\n",
    "# Evaluate ensemble model\n",
    "ensemble_pred = ensemble_clf.predict(X_test_tfidf)\n",
    "ensemble_accuracy = accuracy_score(test_data['label_column'], ensemble_pred)\n",
    "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
